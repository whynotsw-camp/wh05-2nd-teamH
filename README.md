# 📝 프로젝트 기획서

## 📌 프로젝트 명: <span style="font-size:1.5em; font-weight:bold;">JOB자</span>

> **"취업 준비의 동반자, JOB자!"**  
> 사회초년생 구직자들을 위한 **AI 기반 취업 정보 분석 및 맞춤 추천 서비스**

---
## 1. 🎯 프로젝트 정의

- **📌 목표**:  
  사회초년생 구직자들에게 **효율적이고 개인화된 정보를 제공**하여,
  취업 준비를 **체계적으로 수행할 수 있도록 지원**하는 AI 기반 서비스 개발

- **🔧 주요 기능**:
  - 📊 **채용공고 분석**: 자연어 처리 기반 요구조건 추출
  - 🤖 **맞춤 직무 추천**: 이력/기술 기반 AI 직무 매칭
  - 💼 **맞춤 공고 추천**: 관심 직무와 역량 기반 채용공고 추천
  - 🗺 **개인별 취업 로드맵 제공**: 목표 직무에 따른 역량 단계별 제안

---
## 2. 🗂 주요 내용

- 📅 **프로젝트 기간**: `2025-04-05` ~ `2025-08-02`  
- 🧑‍💻 **개발 중심 키워드**:  
  `채용공고 수집` · `추천 알고리즘` · `직무 로드맵` · `대시보드 시각화`

  
<h2 align="center">팀 구성</h2>

<table align="center" width="100%">
  <tr>
    <td align="center" width="250">
      <img src="https://github.com/user-attachments/assets/b77fbacc-6bc4-4757-99ec-d52bc00d02d4" width="160" /><br />
      <b>서동겸(Team Leader)</b>
      <div style="margin:6px 0;">──────</div>
      <i>Data Engineer / Backend</i>
      <div style="margin:6px 0;">──────</div>
      <a href="https://github.com/whynotswdg" target="_blank">
        <img src="https://img.shields.io/badge/GitHub-181717?style=flat-square&logo=github&logoColor=white" />
      </a>
    </td>

  <td align="center" width="250">
      <img src="https://github.com/user-attachments/assets/e948675d-a30b-4121-9ec3-1bdbf41f3849" width="160" /><br />
      <b>김찬호</b>
      <div style="margin:6px 0;">──────</div>
      <i>Backend / Data Engineer / Data Scientist</i>
      <div style="margin:6px 0;">──────</div>
      <a href="https://github.com/kkch1012" target="_blank">
        <img src="https://img.shields.io/badge/GitHub-181717?style=flat-square&logo=github&logoColor=white" />
      </a>
    </td>

  <td align="center" width="250">
      <img src="https://github.com/user-attachments/assets/fe073da8-4e91-4475-bd27-111011ecebbd" width="160" /><br />
      <b>이성재</b>
      <div style="margin:6px 0;">──────</div>
      <i>Frontend / Backend</i>
      <div style="margin:6px 0;">──────</div>
      <a href="https://github.com/sungjae0309" target="_blank">
        <img src="https://img.shields.io/badge/GitHub-181717?style=flat-square&logo=github&logoColor=white" />
      </a>
    </td>

  <td align="center" width="250">
      <img src="https://github.com/user-attachments/assets/6f243740-f574-44e0-bb97-2fbbae396a5d" width="160" /><br />
      <b>김민지</b>
      <div style="margin:6px 0;">──────</div>
      <i> Data Analyst / Data Scientist </i>
      <div style="margin:6px 0;">──────</div>
      <a href="https://github.com/kkuni-jjang" target="_blank">
        <img src="https://img.shields.io/badge/GitHub-181717?style=flat-square&logo=github&logoColor=white" />
      </a>
    </td>
  </tr>
</table>




---

## 🗓️ 3. 일정 계획

![팀 프로젝트 Gantt 차트](https://github.com/user-attachments/assets/75166aef-4750-47f5-ad74-18fae82a57f1)

| 작업 항목                  | 시작 날짜   | 종료 날짜   | 기간(일) |
|---------------------------|------------|------------|----------|
| 프로젝트 선정              | 2025-04-01 | 2025-04-14 | 14       |
| 기획서 작성               | 2025-04-08 | 2025-04-21 | 14       |
| DB 설계                   | 2025-04-29 | 2025-05-05 | 7        |
| 시스템 아키텍처 설계       | 2025-05-06 | 2025-05-19 | 14       |
| 추천 모델 설계            | 2025-05-13 | 2025-05-26 | 14       |
| 챗봇 설계                 | 2025-05-20 | 2025-06-02 | 14       |
| 공고 추천 알고리즘 개발    | 2025-06-03 | 2025-06-23 | 21       |
| 프론트엔드 개발           | 2025-06-03 | 2025-06-16 | 14       |
| 백엔드 개발               | 2025-06-10 | 2025-06-30 | 21       |
| 챗봇 개발                 | 2025-06-17 | 2025-07-07 | 21       |
| 전체 통합 및 테스트        | 2025-07-01 | 2025-07-21 | 21       |
| 서버 배포                 | 2025-07-08 | 2025-07-21 | 14       |
| 최종 발표 자료 및 보고서 작성 | 2025-07-15 | 2025-07-31 | 17       |
| **📢 프로젝트 발표**       | **2025-08-02** | **2025-08-02** | **1**   |


-----------------------------

# 📌 작업 분할 구조 (WBS)

## 단계별 작업 내용

### 1. 기획 및 요구사항 정의
1.1. 프로젝트 목적 및 범위 정의  
1.2. 주요 기능 도출 (직무 분석, 공고 추천, 로드맵 제공 등)  
1.3. 요구사항 수집 및 기능 명세 작성   

### 2. 데이터 정의 및 수집
2.1. 채용공고 데이터 구조 정의 (공고, 자격요건, 우대사항 등)  
2.2. 데이터 수집 아키텍처 설계 (크롤링, API 등)  
2.3. 공고 데이터 수집 자동화 및 저장  
2.4. 수집된 데이터 전처리 및 정제  

### 3. 분석 및 모델링
3.1. NLP 기반 채용공고 분석 (직무 키워드 추출, 임베딩 등)  
3.2. 요구사항 통계 시각화 (직무별 스킬 빈도 등)  
3.3. 사용자 기반 직무/공고 추천 모델 개발  
3.4. 취업 로드맵 알고리즘 설계 및 구성  

### 4. 시스템 구현
4.1. 프론트엔드 UI/UX 설계 및 개발  
4.2. 백엔드 API 및 DB 구축  
4.3. 챗봇 기능 연동 (이력서 피드백 등)  
4.4. 추천 시스템, 로드맵, 대시보드 통합  

### 5. 테스트 및 배포
5.1. 기능별 통합 테스트  
5.2. 사용자 시나리오 기반 테스트  
5.3. 서버 배포 및 버그 수정  
5.4. 최종 발표 및 보고서 작성  

---------------------------

# 📄 요구사항 정의서

## 1. 기능 요구사항 (Functional Requirements)

| 분류       | 기능                      | 설명 |
|------------|---------------------------|------|
| 채용 분석  | 직무별 요구사항 분석       | NLP/LLM 기반으로 채용공고에서 필수 스킬, 경험 등을 자동 추출 및 요약 |
|            | 요구사항 통계 시각화       | 직무별 요구 스킬 빈도, 트렌드 등을 그래프 형태로 시각화 제공 |
| 공고 추천  | AI 채용 공고 추천          | 사용자 이력 및 선호 정보 기반으로 공고 매칭 및 우선순위 추천 |
|            | 추천 사유 제공             | 역량과 요구사항 간 일치 항목에 대한 매칭 사유 설명 |
| 직무 추천  | AI 직무 추천               | 이력, 경험, 기술 등을 분석해 최적 직무(직군/도메인) 자동 추천 |
| 로드맵     | 맞춤형 취업 로드맵 생성     | 사용자의 목표 직무에 따른 역량 분석 → 단계별 로드맵 제공 |
|            | 자료 및 가이드 제공         | 자격증, 기술, 학습자료, 실습 정보 등 단계별 학습 가이드 |
| 사용자 관리| 마이페이지                 | 이력 수정, 지원 기록, 추천 기록 열람 가능 |
| 공고 탐색  | 채용공고 검색              | 직무, 지역, 기업 등 기준으로 상세 필터링 및 탐색 가능 |
| 대시보드   | 통합 분석 대시보드         | 사용자 활동, 추천 내역, 트렌드 등을 시각적으로 제공 |
| 자동 수집  | 공고 자동 수집 및 분석      | 채용 공고를 매일 자동 수집하여 분석 및 데이터화 |

---

## 2. 비기능 요구사항 (Non-Functional Requirements)

| 항목         | 요구사항 내용 |
|--------------|--------------|
| 처리 성능    | 수집된 채용공고 데이터의 전처리 및 분석은 1시간 이내 완료되어야 함 |
| 확장성       | 다양한 외부 채용 플랫폼(API, 웹크롤링 등)과의 연동이 용이해야 함 |
| 가용성       | 서비스는 24시간 안정적으로 운영되어야 하며, 월 평균 가용률 99% 이상 유지 |
| 보안         | 사용자 이력 및 추천 결과는 암호화 저장되며 접근 권한에 따라 관리되어야 함 |
| 유지보수성   | 신규 직무/공고 포맷 추가 시 최소 수정으로 반영 가능해야 함 |


---------------------------
# 📐 프로젝트 설계서

## I.  데이터 아키텍처

### 1. 설계 개요

- **데이터 처리 방식:** 🌀 Batch 처리 (ELT: Extract, Load, Transform)
- **데이터 수집:**  
  - 📡 채용 플랫폼 API 우선 사용  
  - 웹 스크래핑 도구: Scrapy, Selenium, BeautifulSoup  
  - 💡 Scrapy 우선, 동적 페이지는 Selenium 보완
- **데이터 저장:**  
  - 🗂 **원시 데이터 (Data Lake):**  
    - AWS S3에 Parquet 또는 JSON으로 저장  
    - 이미지 = S3 / 메타데이터 = Parquet  
  - 🧮 **변환된 데이터 (Data Warehouse):**  
    - 정제 후 AWS Redshift에 저장 (프로토타입: PostgreSQL)
- **분석 및 처리:**  
  - ⚙️ Spark on AWS EMR  
  - 🔍 NLP(KeyBERT, KoBERT), 이상치 제거, 중복 제거  
  -  Apache Airflow로 ELT 파이프라인 자동화 및 모니터링

### 2. 기술 스택

- **데이터 수집:** 🐍 Python (Scrapy, Selenium, Requests 등), 채용 API  
- **분석/처리:** AWS S3, EMR, Redshift, Spark, KeyBERT, KoBERT, Airflow  
- **시각화 및 로깅:** 📊 QuickSight, Airflow UI

---

## II. 🔗 데이터 연동 정의서

### 1. 데이터 정의

- **데이터 소스:**
  - 🛰 채용 플랫폼 API  
  - 🕸 채용 관련 웹사이트 스크래핑
- **주요 컬럼 예시:**
  - **채용공고:** 회사명, 직무, 요건, 우대사항, 기술스택, 마감일 등  
  - **구직자:** 이름(암호화), 경력, 학력, 기술스택, 희망직무 등

### 2. 연동 방식

| 항목         | 설명                                                                 |
|--------------|----------------------------------------------------------------------|
| 연동 방식    | 🔁 Batch 수집                                                       |
| 연동 대상    | 외부 채용공고 API, 크롤링 대상 웹사이트                             |
| 연동 주기    | ⏰ 매일 자정 (공고 업데이트 정책에 따라 유동 조정)                 |
| 적재 방식    | 🛠 Staging 테이블 → 전처리 후 통합 테이블로 이관                     |
| 예외 처리    | 🚫 마감일 경과, 필수값 누락, 중복 공고 제외                          |

---

## III. ☁️ 클라우드 아키텍처 설계서

### 1. 아키텍처 개요

- **사용 서비스 (AWS 중심):**
  - 🗃 **데이터 저장:** AWS S3  
  - ⚙️ **처리 및 분석:** Apache Spark (EMR), Redshift or PostgreSQL  
  - 📊 **워크플로우:** Apache Airflow (AWS MWAA)  
  - 🚀 **배포 및 인프라:** Docker, GitHub Actions, Jenkins, EC2, IAM, VPC 등

-------------------------

# 🖥 화면 구성

## 🎬 시연 영상

[![시연 영상 바로 보기](https://img.youtube.com/vi/SOFaN2uuX6A/0.jpg)](https://youtu.be/SOFaN2uuX6A?si=tfUmHJDmbQaMv3Cb)

> 📺 클릭 시 유튜브에서 전체 시연 영상을 확인할 수 있습니다.

---
## 📌 주요 화면 캡처

<table align="center">
  <tr>
    <td align="center">
      <img src="https://github.com/user-attachments/assets/b84e7341-a390-4e06-a775-df1df091da89" width="400" />
    </td>
    <td align="center">
      <img src="https://github.com/user-attachments/assets/291710bb-981d-4a1a-be6f-7befdc183d3e" width="400" />
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="https://github.com/user-attachments/assets/45c9fe4a-dd99-4e6f-90a3-c78108e3d7c0" width="400" />
    </td>
    <td align="center">
      <img src="https://github.com/user-attachments/assets/b2b640f8-a253-40f2-866d-fe3b5e7984f9" width="400" />
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="https://github.com/user-attachments/assets/d946675c-8062-45da-bba0-b8ea968628c7" width="400" />
    </td>
    <td align="center">
      <img src="https://github.com/user-attachments/assets/2718ace5-e16e-4d4a-a430-9b91c21cd8d7" width="400" />
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="https://github.com/user-attachments/assets/4bd392d7-6245-4e2f-a658-83e6db388525" width="400" />
    </td>
    <td align="center">
      <img src="https://github.com/user-attachments/assets/7032f2e9-f9f3-4633-a70d-8f6dce0fbdb5" width="400" />
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="https://github.com/user-attachments/assets/d713daa2-a6a8-4dc9-893c-e443bd97d7c2" width="400" />
    </td>
    <td align="center">
      <img src="https://github.com/user-attachments/assets/9f425df3-3752-4317-aba2-34824c23eb6b" width="400" />
    </td>
  </tr>
</table>





--------------------------

## 💭 회고록 (Retrospective)

이번 프로젝트를 통해 팀원 각자가 맡은 역할에서 어떤 성과와 고민이 있었는지 회고하며, 다음 프로젝트를 위한 인사이트를 정리했습니다.

---

### 서동겸 (데이터 엔지니어)

#### ✅ 잘한 점
- 웹 스크래핑 기반 데이터 수집 자동화 구현
- DOM 구조 변화에 유연하게 대응할 수 있는 수집 전략 고안

#### ⚠️ 개선이 필요한 점
- 설계 단계에서의 기술적 경험 부족
- 스크래핑 코드 유지보수가 어려워 구조 변경에 취약함

#### 📚 배운 점
- 데이터 엔지니어 역할에 대한 실무적 감각 향상
- OCR 도구 성능 비교 및 구조 변화 대응 전략 습득

#### 🚀 다음 단계
- 스크래핑 코드의 모듈화 및 DOM 구조 변화 감지 시스템 구축
- 이미지 기반 공고 대응을 위한 OCR 최적화 전략 수립

---

### 김찬호 (백엔드 개발자)

#### ✅ 잘한 점
- 데이터 처리를 원활하게 할 수 있는 모델링 전략 구상
- 모델링이나 전체적인 프로젝트의 기능 커뮤니케이션 및 의견 제시

#### ⚠️ 개선이 필요한 점
- 모델링 관련 전문 지식 부족
- 전체적인 일정 관리 미흡으로 활동 효율성 저하

#### 📚 배운 점
- 핵심 키워드 추출 및 임베딩을 위한 기술 경험 습득
- 전처리 및 자연어 처리(NLP)에 대한 실질적 이해도 향상

#### 🚀 다음 단계
- 전처리 자동화 도구 도입 검토
- 키워드 임베딩 및 추천 시스템 통합

---

### 이성재 (프론트엔드 개발자)

#### ✅ 잘한 점
- 사용자 맞춤 UI 및 UX 제작
- 프론트 - 백엔드 연결하여 데이터 흐름과 API 설계에 대한 감을 익힘

#### ⚠️ 개선이 필요한 점
- 초기에 기능 단위로 커밋하지 않고 작업을 몰아서 하다가 변경 이력이 추척하기 어렵게 만듦
- 다음 프로젝트에선 작은 단위로 자주하는 습관을 들일 것

#### 📚 배운 점
- DJango 모델 변경 후의 마이크레이션 과정에서 발생할 수 있는 문제와 그 해결 방법을 체득함

#### 🚀 다음 단계
- GitHub Actions 혹은 Vercel 등을 활용한 CI/CD 자동화 적용 경험도 추가해보고자 함

---

### 김민지 (데이터 분석가 / 데이터 사이언티스트)

#### ✅ 잘한 점
- 데이터 시각화 및 유사도 분석, 상관관계 분석 등 통계적 기법을 프로젝트에 효과적으로 적용
- 복잡한 데이터를 시각적으로 잘 표현하여 팀의 이해도 향상

#### ⚠️ 개선이 필요한 점
- keyBERT 모델 튜닝 부족 및 성능 한계
- LLM 및 Multilingual Embedding 모델 활용으로 높은 정확도의 전처리와 유사도 계산을 할 예정

#### 📚 배운 점
- 통계 기법 외 LLM, 다국어 임베딩 모델 활용 가능성 인식
- 다양한 키워드 기반 유사도 분석 접근법에 대한 실험 경험

#### 🚀 다음 단계
- LLM 기반 전처리 강화 및 다국어 임베딩 실험
- 키워드 추출 파이프라인 고도화 및 정확도 개선

---



